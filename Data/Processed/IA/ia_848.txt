2 / 2I have to work on an AI project. From now on, I will explain the project I have to do. The data is divided into three parts. 1. Training data: train.csv 2. Test data: test.csv 3. Submission file: sample_submission.csv The train.csv file consists of 3 columns of id, text and label, and the test.csv file consists of 2 columns of id and text. The sample_submission.csv file consists of id and label columns. Label consists of a total of 8, and the text column consists of news article data. Write code to train and infer a model that classifies it as a catboost model. Don't do train_test_split. Set catboost's parameters : iterations to 200, learning_rate to 0.5, loss_function to 'MultiClass', thread_count to -1, random_state to 42. When indexing text column, you must make dataframe for pandas list indexing, not series. When making the Pool, you must specify text_features argument, the list of column names of texts. You should read sample_submission.csv with pandas and flatten prediction results for numpy method. Give me a code for above description.

Sure, here's a code that meets your requirements: Note that this code assumes that the file paths for the data files are in the same directory as the Python script. If that's not the case, you'll need to modify the file paths accordingly.

6 / 6Use hyperopt, 3-StratifiedKFold, macro-f1-score to optimize model above. Optimize parameters iterations, learning_rate, depth, l2_leaf_reg. Use uniform or quniform distribution for search space. And you should use GPU for training catboost model. Finally, you should make submission file.

Sure, here's a code that uses hyperopt and 3-StratifiedKFold to optimize the CatBoost model parameters and generates a submission file:

Finally, you should make submission file for model and test_pool in code above.

Sure, here\