2 / 2I have to work on an AI project. From now on, I will explain the project I have to do. The data is divided into three parts. 1. Training data: train.csv 2. Test data: test.csv 3. Submission file: sample_submission.csv The train.csv file consists of 3 columns of id, text and label, and the test.csv file consists of 2 columns of id and text. The sample_submission.csv file consists of id and label columns. Label consists of a total of 8, and the text column consists of news article data. Write code to train and infer a model that classifies it as a catboost model. Don't do train_test_split. Set catboost's parameters : iterations to 200, learning_rate to 0.5, loss_function to 'MultiClass', thread_count to -1, random_state to 42. And use gpu for training. When indexing text column, you must make dataframe for pandas list indexing, not series. When making the Pool, you must specify text_features argument, the list of column names of texts. You should read sample_submission.csv with pandas and flatten prediction results for numpy method. Give me a code for above description.

Sure, here's the code for the project you described: This code loads the training, testing, and submission data from CSV files, sets the features and target columns, creates the CatBoost pool with the specified parameters, trains the model on the training data, makes predictions on the test data, flattens the predictions, and saves them to the submission file.

4 / 4Use hyperopt, train_test_split test rate of 0.2, macro-f1-score to optimize model above. Optimize parameters iterations, learning_rate, l2_leaf_reg, model_size_reg, max_depth. Use uniform or quniform distribution for search space. Do not use eval_metric. Finally, you should make submission file.

Sure, here's the updated code that uses hyperopt to optimize the model and a train_test_split with a test rate of 0.2 to evaluate the model's performance. The macro-f1-score is used as the objective function to optimize. This code first loads the training, testing, and submission data from CSV files and defines the features and target columns. Then it splits the data into training and validation sets using train_test_split. Next, the search space for hyperopt is defined, which includes the parameters iterations, learning_rate, l2_leaf_reg, model_size_reg, and max_depth. The objective function is defined as the macro-f1-score calculated on the validation set. The hyperopt algorithm is