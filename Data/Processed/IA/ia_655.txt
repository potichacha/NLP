one of the key reasons why models like GPT are not considered sentient or conscious is because the models cannot have subjective experiences. however, GPT models are trained using RLHF, a feedback loop with real humans, and the model continuously learns from the interactions it has with people as it intakes information about these interactions from new data. its arguable that humans also learn from a similar pattern of human evaluation and feedback. the development of our ability to "think" is strongly tied to the relationships and interactions we have with other people. how is this different from the process that GPT goes through?