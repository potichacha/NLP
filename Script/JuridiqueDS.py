from datasets import load_dataset
import os
import logging

# === CONFIGURATION ===
DATASET_NAME = "harvard-lil/cold-french-law"
OUTPUT_DIR = "../Data/Processed/Juridique"
os.makedirs(OUTPUT_DIR, exist_ok=True)

MAX_FILES = 1000
MAX_CHARS = 3000

# === LOGGING ===
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logging.info("‚öñÔ∏è D√©but de l'extraction du dataset juridique")

# === Chargement en streaming
dataset = load_dataset(DATASET_NAME, split="train", streaming=True)
logging.info(f"üì¶ Dataset '{DATASET_NAME}' charg√© en mode streaming.")

# === Traitement
count = 0
for row in dataset:
    texte = row.get("article_contenu_text")
    
    if isinstance(texte, list):
        texte = " ".join(texte)
    if not texte or len(texte) < 200:
        logging.debug("‚è© Texte trop court ou vide, ignor√©")
        continue

    trimmed = texte[:MAX_CHARS].strip()

    try:
        with open(os.path.join(OUTPUT_DIR, f"juridique_{count + 1}.txt"), "w", encoding="utf-8") as f:
            f.write(trimmed)
        logging.info(f"‚úÖ Article {count + 1} sauvegard√©")
        count += 1
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Erreur sauvegarde fichier {count + 1}: {e}")
        continue

    if count >= MAX_FILES:
        break

logging.info(f"üèÅ Extraction termin√©e : {count} fichiers juridiques sauvegard√©s dans '{OUTPUT_DIR}'")